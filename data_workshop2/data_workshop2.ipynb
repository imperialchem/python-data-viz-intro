{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Plotting and Data Analysis in Python 2\n",
    "Clyde Fare and Jo√£o Pedro Malhado, Imperial College London (contact: [python@imperial.ac.uk](python@imperial.ac.uk))\n",
    "\n",
    "Parts of the material of this notebook have been addapted from work by Andrew McKinley, Nial Jackson and Oliver Robotham. This notebook is licensed under a [Creative Commons Attribution 4.0 (CC-by) license](http://creativecommons.org/licenses/by/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop we will cover how to load data from files and we will see how to perform some statistical analysis on this data.\n",
    "We ill also investigate the properties of statistical distributions which are visualized via histograms, and see how the properties of these distributions relate to basic statistical quantities.\n",
    "\n",
    "Once more, this is an interactive tutorial - as you go through it any time you see something that looks like this:\n",
    "\n",
    "    a = \"Hello\"\n",
    "   \n",
    "that's followed by an empty *code cell* (a light grey rectangle with a label like *\"In[ ]\"*), you should \n",
    "type the expression in the code cell, hit Shift+Return to *execute* it, and note the output.\n",
    "\n",
    "Limit copying and pasting to cells requiring more than 5 lines! You'll learn the concepts better if you type them out yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap from workshop 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are working inside an interactive Python Notebook. It is composed of code cells where Python code can be executed and non code cells, where descriptive material can be placed.\n",
    "\n",
    "The icons at the top of the page allow us to save the page, add new cells, cut, copy and paste cells, move cells up or down, execute the highlighted cell, halt and reset the current python kernel.\n",
    "\n",
    "We can convert a highlighted cell to a different type of cell using the dropdown menu to the immediate right of the icons.\n",
    "\n",
    "We can execute a code cell/render a markdown cell with Shift+Return.\n",
    "\n",
    "If we want to have direct access to the plotting and numerical functions and include our plots directly in the notebook we need to execute\n",
    "\n",
    "    %pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help us visualize some of the data we will add another command that sets how many lines is to display variables\n",
    "\n",
    "    set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables, allow us to refer to data objects with names. Before you execute the cell - can you predict the value of z?\n",
    "    \n",
    "    x=3\n",
    "    y=array([1,2,3])\n",
    "    z=x*y\n",
    "    z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays are collections of numbers, that we can operate on collectively and are the containers for our data. There are special commands **linspace** and **arange** for creating arrays.\n",
    "\n",
    "**linspace** creates arrays of equally spaced numbers where we specify the initial value, the final value and how many numbers we want inbetween\n",
    "\n",
    "    linspace(-pi, pi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**arange** creates arrays of equally spaced numbers where we specify the initial value, a stop value (that will not be included), and the interval size:\n",
    "    \n",
    "    arange(0, 20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can refer to elements of the data in an array by using square brackets and the index of the element we want.\n",
    "\n",
    "Set the variable *my_1D_array* to be equal to the array in the cell above this one, and output the first element of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the 4th element of *my_1D_array*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also refer to subsets of the data by providing two indices separated by a colon:\n",
    "\n",
    "    my_1D_array[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the above slice takes element 0 of *my_1D_array* **up to but not including** element 5.\n",
    "\n",
    "* If the first index is omitted, the subset will start at the zeroth index.\n",
    "* If the second index is omitted the subset will extend to the last element\n",
    "\n",
    "Thus\n",
    "\n",
    "    my_1D_array[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose to omit certain elements in our subset by using a second colon and a step size\n",
    "\n",
    "    my_1D_array[0:10:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays can be multidimensional\n",
    "\n",
    "    my_2D_array = array([[0, 3, 6, 9], [1, 4, 7, 10], [2, 5, 8, 11], [3, 6, 9, 12]])\n",
    "    my_2D_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format for selecting elements from a 2D array is:  \n",
    "\n",
    "**<span style='color:green'>array_name</span> [ <span style='color:blue'>row_indices</span> <span style='color:red;font-     weight:bold'>,</span> <span style='color:blue'>column_indices</span> ]**\n",
    "\n",
    "\n",
    "E.g. to select all rows and from them the columns from index 2 up to but not including index 4 would be: \n",
    "    \n",
    "    my_2D_array[:,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also include steps. Try to predict what the following command will produce:\n",
    "    \n",
    "    my_2D_array[1:4:2,0:3:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following diagram summarises the indexing for 2D arrays.\n",
    "\n",
    "**Make sure you understand everything on this diagram**\n",
    "\n",
    "![If you don't seen an image you may not be running the notebook on the same folder as the image files.](numpy_indexing.png \"Illustration of array row/column indexing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform mathematical operations on arrays, which performs the operation on all elements of the array\n",
    "\n",
    "    sin(my_1D_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot using the **plot** command which accepts many keywords, and display using the **show** command. First we'll create some arrays:\n",
    "\n",
    "    age = arange(10)\n",
    "    p_human = age**2\n",
    "    p_badger = age**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    p_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    p_badger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the arrays we have created:\n",
    "    \n",
    "    plot(age, p_human, linewidth=2.5, linestyle=\"--\", label='Humans')\n",
    "    plot(age, p_badger, marker='^', color='red', label='Badgers',linestyle='None' )\n",
    "    title('My reminder plot')\n",
    "    xlabel('Age')\n",
    "    ylabel('Power')\n",
    "    legend()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many occasions where we want to plot data on a logarthimic scale. To illustrate this, in the next code cell we define the variable *r_data* with some radioactivity data for the radioactive elements. The first column contains the atomic numbers of the elements and the second column contains the half lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_data = array([[  43,   1.29928320e+14],\n",
    "               [  61,   5.59133280e+08],\n",
    "               [  83,   5.99184000e+26],\n",
    "               [  84,   3.21982560e+09],\n",
    "               [  85,   2.90160000e+04],\n",
    "               [  86,   3.30349968e+05],\n",
    "               [  87,   1.30200000e+03],\n",
    "               [  88,   5.01422400e+10],\n",
    "               [  89,   6.87059064e+08],\n",
    "               [  90,   4.43396160e+17],\n",
    "               [  91,   1.03400237e+12],\n",
    "               [  92,   1.40997456e+17],\n",
    "               [  93,   6.76604880e+13],\n",
    "               [  94,   2.50080480e+15],\n",
    "               [  95,   2.32987968e+11],\n",
    "               [  96,   4.91961600e+14],\n",
    "               [  97,   4.34881440e+10],\n",
    "               [  98,   2.84013216e+10],\n",
    "               [  99,   4.07508192e+07],\n",
    "               [  100,   8.68320000e+06],\n",
    "               [  101,   4.44960000e+06],\n",
    "               [  102,   1.00080000e+04],\n",
    "               [  103,   3.60000000e+04],\n",
    "               [  104,   4.71600000e+04],\n",
    "               [  105,   2.00160000e+04],\n",
    "               [  106,   6.98400000e+03],\n",
    "               [  107,   5.40000000e+03],\n",
    "               [  108,   3.99600000e+03],\n",
    "               [  109,   1.80000000e+03],\n",
    "               [  110,   2.40000000e+02],\n",
    "               [  111,   6.00000000e+02],\n",
    "               [  112,   2.40000000e+03],\n",
    "               [  113,   1.20000000e+03],\n",
    "               [  114,   7.98000000e+01],\n",
    "               [  115,   6.00000000e+01],\n",
    "               [  116,   1.20000000e-01],\n",
    "               [  117,   5.00000000e-02],\n",
    "               [  118,   5.00000000e-03]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we simply plot atomic number versus half life. What we see is not very informative:\n",
    "\n",
    "    atomic_nos = r_data[:,0]\n",
    "    half_lives = r_data[:,1]\n",
    "    plot(atomic_nos, half_lives)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the half lives we can see why:\n",
    "    \n",
    "    half_lives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that they range from 10<sup>-3</sup> for Ununoctium to 10<sup>26</sup> seconds for Bismuth - 29 orders of magnitude! Because of this guargantuan range of values plotting the raw data reveals almost nothing. The plot is dominated by the half life of Bismuth and none of the other variation is visible.\n",
    "\n",
    "If we scale the y-axis so that it is logarithmic i,e the units are orders of magnitude then we should have a much better way to visualize the data. We can use the **xscale** and **yscale** functions to do this.\n",
    "\n",
    "    yscale('log')\n",
    "    plot(atomic_nos, half_lives, marker='o')\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which allows us a much better visualization of the data.\n",
    "\n",
    "The above is equivalent to\n",
    "\n",
    "    plot(atomic_nos, log10(half_lives), marker='o')\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot using logarithmic scaling for one axis and normal linear scaling for another is known as a semi-log plot. It is also possible to create a log-log plot by scaling both axis. This can be useful to pull out linear relationships in otherwise non-linear data. We will see an example of this in workshop 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing data to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common use case you will have when plotting data is plotting data that has been generated elsewhere.  Most modern measuring instruments will be coupled to a computer or otherwise will be able to store your data in a file. **You should always aim to store your measurement data in a text file**. That means you need a way to load data into a notebook.\n",
    "\n",
    "There are severeal ways of doing this, the simplest is **loadtxt**\n",
    "\n",
    "This loads data from text files, provided the data layed out in a regular format. If you take a look at the file [data.txt](./data.txt) which is in the same directory as this notebook. You will see each lines contains numbers separated by spaces.\n",
    "\n",
    "loadtxt will load this data into an array for us via:\n",
    "\n",
    "    our_data = loadtxt(\"data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    our_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could load a text file seperated by commas like [data2.txt](./data2.txt) via:\n",
    "    \n",
    "    loadtxt(\"data2.txt\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now modify the data we just loaded by shifting all the values by -2 and save it back to a file.\n",
    "\n",
    "    modified_data = our_data - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to save the modified data array we can use the command **savetxt**, which works analagously to loadtxt thus\n",
    "    \n",
    "    savetxt('my_data_file.txt', modified_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the file my_data_file.txt, with the data values separated by spaces.\n",
    "\n",
    "If we wanted data separated by commas we would use:\n",
    "    \n",
    "    savetxt('my_data_file2.txt', modified_data, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the two files you've just produced: [my_data_file.txt](./my_data_file.txt) and [my_data_file2.txt](./my_data_file2.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file d1.dat contains data we will be using in this section. Although it contains the unspecific *dat* extension (the 3 letter after the point in the file name), you can open it with a text editor such as notepad. By doing that, you see that it is indeed a text file containing a series of numbers.\n",
    "\n",
    "Use the loadtxt function to load the content of d1.dat, and store it on the variable *d*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now plot a histogram of the data set contained in the file\n",
    "\n",
    "    hist(d)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms tell us how many data points there are in a particular range of the data. By default the *hist* command creates 10 bins, equally spaced between the lowest value in the data set and the highest value in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the functions **min** and **max** to find the largest and smallest values in an array.\n",
    "\n",
    "    min(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    max(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armed with these values we can check our histogram makes sense. We said before there were 10 bins by default, now that we know the maximum and minimum values we can see that the bin size must be:\n",
    "    \n",
    "    ( max(d) - min(d) )/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note we had to use brackets because we want the subtraction to occur before the division.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The width of each bin is about 0.75 and we start at about -3.66 and end at about 3.8. Look at the above histogram and make sure that this makes sense - where do you expect the third bin from left to start?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the number of bins using the the bin keyword:\n",
    "    \n",
    "    hist(d, bins=22)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many options to customise histograms, we won't go through them all. But this is a good point to demonstrate a way to use the built in help system. We can automatically get more information on a particular function by typing the function followed by a question mark:\n",
    "    \n",
    "    hist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pops up a footer window that has lots of information. It defines all the keywords and explains what form they take and what their effect is. You won't yet be able to understand everything that the helper utility tells you but it can still be a very useful resource. \n",
    "\n",
    "Another way to get the same information, is to type the function name (**hist** in this case) and then press the key combination SHIFT+TAB. Try it in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a floating pop up with the same information, you can press the plus icon in the top right of the popup to expand. If you want to reopen the pop up you can simply delete the first opening parenthesis and put it back. Try it on the line above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pylab gives us access to basic statistical functions like the sample mean, defined as\n",
    "\n",
    "$$\\bar{x}=\\frac{\\sum_i^N x_i}{N} ,$$\n",
    "\n",
    "where $x_i$ is the value of each element and $N$ is the total number of data points.\n",
    "\n",
    "    mean(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median:\n",
    "   \n",
    "   \n",
    "    median(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample standard deviation defined as\n",
    "\n",
    "$$s_x=\\sqrt{\\frac{\\sum_i^N(x_i-\\bar{x})^2}{N-1}}$$\n",
    "    \n",
    "    std(d,ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the *ddof=1* parameter set above which relates to the *N-1* term in the denominator in the definition of standard deviation. Different values of *ddof* have different statistical meaning. We will be dealing exclusivelly with *ddof=1*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentile:\n",
    "    \n",
    "    first_q = percentile(d,25)\n",
    "    third_q = percentile(d,75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That can be used to compute the interquartile range:\n",
    "    \n",
    "    third_q - first_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **standard error of the mean** $\\sigma_{\\bar{x}}$ is an important quantity which we will see again in the exercise below. It expresses how uncertain we are in the mean value we have computed. When reporting an estimate resulting from several measurements, we should use $\\bar{x} \\pm \\sigma_{\\bar{x}} units$.\n",
    "\n",
    "We can calculate the standard error from the standard deviation and the square root of the number of elements:\n",
    "\n",
    "$$\\sigma_{\\bar{x}}=\\frac{s_x}{\\sqrt{N}}=\\sqrt{\\frac{\\sum_i^N (x_i-\\bar{x})^2}{N(N-1)}}$$\n",
    "\n",
    "To compute the number of elements we need another built-in function **len**\n",
    "\n",
    "    no_elements = len(d)\n",
    "    std(d,ddof=1)/no_elements**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform these statistical measures on 2D arrays (i.e. matrices), we'll make a 2D array using a function **randn**. This generates arrays of random numbers, to make a 5x5 array of random numbers we would use\n",
    "\n",
    "    m=randn(5,5)\n",
    "    m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take the mean directly we get the mean of all the numbers in the matrix, in much the same way that we would for a 1d array:\n",
    "    \n",
    "    mean(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However with a matrix we have the possibility to compute the means of all the columns, or all the rows individually. We do this with the axis keyword. To compute the mean of each column we would use:<a id=\"axis\"></a>\n",
    "    \n",
    "    mean(m, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us an array where the first element is the mean of the first column of the 2D array, the second element is the mean of the second column of the 2D array etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change now the axis value to 1 to compute the mean of each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same is true of the other statistical functions.\n",
    "\n",
    "    std(m, ddof=1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the many ways to access the elements of an array that we covered in the previous workshop there is a final method that is very useful. Here we access a subset of the data not by specifying the *indices* we want to include but instead by specifying their *values*. Thus we can select all elements of an array that are greater than a certain value. This is very useful to filter data in order to remove spurious values and outliers. Recalling that d is the dataset we loaded above. To select all values larger than 3 we use:\n",
    "    \n",
    "    d[d>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be combined with the statistical functions, thus to select data above the mean we would use:\n",
    "    \n",
    "    large_d = d[d>mean(d)]\n",
    "    hist(large_d,bins=22, range=array([-4,4]))\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can chain the filtering process. Thus to select the data inside the interquartile range we first select the data that is above the 25th percentile:\n",
    "    \n",
    "    q1 = percentile(d,25)\n",
    "    last_75_d = d[d>q1]\n",
    "    hist(last_75_d, bins=22, range=array([-4,4]))\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then of that we select the data that is below the 75th percentile:\n",
    "    \n",
    "    q3 = percentile(d,75)\n",
    "    mid_d = last_75_d[last_75_d<q3]\n",
    "    hist(mid_d, bins=22, range=array([-4,4]))\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far we have been filtering a 1 dimensional array but the filering process works just as well if we have a two dimensional array, when we discussed the *loadtxt* function above we loaded some data to a variable named 'our_data':\n",
    "\n",
    "    our_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now filter this data, taking only the lines where the values in the second column are greater than 5:\n",
    "    \n",
    "    column_2 = our_data[:,1]\n",
    "    our_data[column_2>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we'll be dealing with larger datasets, such as those you could have obtained from an automatic measuring instrument, and looking at some statistical properties of sets of measurements.\n",
    "\n",
    "The file measurements.csv contains the data we will be analysing in these exercises. (CSV stands for [comma separated values](https://en.wikipedia.org/wiki/Comma-separated_values), which is a type of text file commonly used in porting data between programs or instruments.) \n",
    "\n",
    "The file contains 5 columns of data corresponding to 100,000 repeated measurements of the same system using 5 different measuring instruments (good thing we don't have to analyse this data by hand!)\n",
    "\n",
    "* Have a look at the file content **using a text editor such as notepad**, and load the file data into a variable. Output the value of the variable to see how the imported data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick and informative way of acquiring an overall view of the data distribution is to plot histograms.\n",
    "\n",
    "* On the same figure, plot 5 histograms of 100 bins for each of the 5 sets of data.\n",
    "* Label the figure and make sure the it is of reasonable size and a legend is present.\n",
    "* Set the *range* keyword of each histogram to be equal such that all histograms are visible, and set the transparency *alpha* keyword to a value less than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measurements are subject to noise thus two consecutive measurements of the same system are unlikely to give exactly the same result even if the system is unchanged, we see this in our dataset.\n",
    "\n",
    "The *mean* $\\bar{x}$ of a set of independent measurements of some property $x$ is the best estimate of the actual value of that property. As we will see below, the precision of this estimate can be improved by increasing the number of measurements we are averaging over. \n",
    "\n",
    "The *standard deviation* $s_x$ quantifies the spread of the experimental measurements about its mean value. (It corresponds to the average error of a single measurement. When writing up experiments you will often report the mean of some set of measurements +/- some error value, it is important to note that the standard deviation is **not** this error value - below we will examine what this error is in more detail.)\n",
    "\n",
    "* For each of the 5 datasets, calculate the mean and the standard deviation (don't forget to set the appropriate *ddof* value). Using the keyword <a href=\"#axis\" style=\"font-style:italic\">axis</a> could be useful in this context.\n",
    "\n",
    "* How do the $\\bar{x}$ and $s_x$ values relate the shape of the distributions in the histograms?\n",
    "\n",
    "* Construct another figure containing the histograms as above but with the following addition: using the mean values you have calculated, add vertical lines marking out the position of the mean for the 5 distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now study how some statistical properties vary with sample size.\n",
    "\n",
    "* For the 1st dataset, construct three histograms on a single figure - one with all 100,000 measurements, one for the first 10,000 measurements, and another for the first 1,000 measurements.\n",
    "\n",
    "* Change the figure so that the histograms are normalized (you will need to use the built in help to discover the appropriate keyword of function **hist** to achieve this).\n",
    "\n",
    "By looking at these three histograms, and by calculating their means and standard deviations, what do you notice about how much the mean value, and the standard deviation change as the sample size grows? (Bear in mind that all these sample sizes are fairly large.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistical uncertainty associated with the mean value is given by the *standard error of the mean* $\\sigma_{\\bar{x}}$ defined above. This is the value that should be reported as the statistical error of your measurements.\n",
    "\n",
    "Let us investigate how this quantity varies with sample size. We will be considering data from instruments 1 and 4, these have similar mean value as you should see in your histograms above.\n",
    "\n",
    "* For datasets 1 and 4, choose 5 sample sizes between 1000 and 100,000 calculate the standard deviation and the standard error.\n",
    "\n",
    "* For the two datasets above, plot the standard deviation and standard error as a function of sample size. (Make sure your plot extends to the maximum sample size of 100,000. You may want to use a logarithmic *y* scale in this plot.)\n",
    "\n",
    "* What does this plot tell you about the usefulness of repeating the same measurement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By drawing a horizontal line in the plot above, make a rough estimate of what sample size is needed in order to report a result with the same degree of uncertainty using measuring instrument 1, as it would be reported using measuring instrument 4 with 100,000 measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final note, from the definition of standard error and the study we just carried out, what is the limit of the standard error value as the sample size goes to infinity? \n",
    "\n",
    "Although this statistical error vanishes for infinite sample sizes, this does not mean you can achieve absolute confidence in your measurements by taking an extremely large number of repetitions. \n",
    "\n",
    "The standard error quantifies our uncertainty due to the presence of random noise. As we have seen we can combat this using a sufficiently large sample size making our estimate more and more precise. There is however a second form of error that influences the accuracy of our estimate and this form is not reduced through repetition: *systematic error*. This corresponds to imperfect/faulty operation of the instruments or miscalibration.\n",
    "\n",
    "Looking at the data produced by our five instruments we see that all the instruments are affected by noise (instrument 5 being the most precise) but that instruments two three and five suffer from systematic errors which push the mean value of their measurements away from the actual value of the system (~2.4) which is correctly captured by instruments one and four. \n",
    "\n",
    "Systematic errors need to be estimated and corrected for based on knowledge of the measurement process and instruments used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reviewed the basic principles of storing and accessing data in arrays and how to plot that data. We looked at how a logarithmic scale can be used to visualize measurements spanning several orders of magnitude. We saw how to load data from, and save data to text files (most instruments should be able to export data in the form of text files). We have seen how simple statistical quantities of data sets can be calculated.\n",
    "\n",
    "We have also looked at the properties of statistical distributions for big sample sizes, and how statistical quantities such as the mean (distribution centre), sample standard deviation (distribution width) and standard error of the mean (uncertainty on the value of the mean) charaterise these distributions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
